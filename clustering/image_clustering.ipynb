{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhhuhGq5p8N8"
   },
   "source": [
    "# **Image Clustering Using VGG16 and CAE** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTax0gl0UO1c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import load_model, Model\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import imageio as io\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train and test data\n",
    "# file_path = [file for file in os.listdir(\"/Users/jennysheng/Documents/museum_images/all_image_data/\") if file.endswith(\".jpg\")]\n",
    "# train_files, test_files = train_test_split(file_path, test_size = 0.05)\n",
    "\n",
    "# train_files = pd.DataFrame(train_files,columns=['filepath'])\n",
    "# test_files = pd.DataFrame(test_files,columns=['filepath'])\n",
    "# train_files.to_csv('/Users/jennysheng/Documents/museum_images/train_file.csv')\n",
    "# test_files.to_csv('/Users/jennysheng/Documents/museum_images/test_file.csv')\n",
    "train_files = list(pd.read_csv('/Users/jennysheng/Documents/museum_images/train_file.csv')['filepath'])\n",
    "test_files = list(pd.read_csv('/Users/jennysheng/Documents/museum_images/test_file.csv')['filepath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTvkTshaWoiZ"
   },
   "outputs": [],
   "source": [
    "def get_model(cae):\n",
    "    if cae:\n",
    "        model = load_model('/Users/jennysheng/Documents/museum_images/encoder_model.h5')\n",
    "        return model\n",
    "    else: \n",
    "        base_model = VGG16(weights='imagenet', include_top=True)\n",
    "        model = Model(inputs=base_model.input,\n",
    "                    outputs=base_model.get_layer('fc2').output)\n",
    "        return model\n",
    "\n",
    "# helper function to get all images into one dict\n",
    "def get_image_files(path_to_files, size, files):\n",
    "    images = []\n",
    "    count = 0\n",
    "    for file in files:\n",
    "        if count%100 == 0:\n",
    "            print(\"Processed \" + str(count) + \" files\")\n",
    "        image = cv2.resize(cv2.imread(path_to_files+file), size)\n",
    "        images.append([file, image])\n",
    "        count += 1\n",
    "    return dict(images)\n",
    "\n",
    "# helper function to get vgg image feature vectors\n",
    "def vgg_feature_vector(image_array, model):\n",
    "  if image_array.shape[2] == 1:\n",
    "    image_array = image_array.repeat(3, axis=2)\n",
    "\n",
    "  array_expanded = np.expand_dims(image_array, axis=0)  \n",
    "  array_expanded = preprocess_input(array_expanded)\n",
    "  return model.predict(array_expanded)[0,:]\n",
    "\n",
    "\n",
    "# helper function to get cae image feature vectors\n",
    "def cae_feature_vector(m, data, layer):\n",
    "    encoded = backend.function([m.layers[0].input],[m.layers[layer].output])\n",
    "    encoded_array = encoded(data[None, :,  :, :])[0]\n",
    "    pooled_array = encoded_array.max(axis=-1)\n",
    "    return encoded_array\n",
    "\n",
    "\n",
    "# helper function to get all feature vectors into a list\n",
    "def feature_vectors(images_dict, model, cae, layer):\n",
    "    if cae:\n",
    "        forward_vector = {}\n",
    "        count = 0\n",
    "        for fn, img in images_dict.items():\n",
    "          if count%100 == 0:\n",
    "              print(\"Processed \" + str(count) + \" vectors\")\n",
    "          forward_vector[fn] = cae_feature_vector(model, img, layer)\n",
    "          count += 1\n",
    "        return forward_vector\n",
    "    else:\n",
    "        forward_vector = {}\n",
    "        count = 0\n",
    "        for fn, img in images_dict.items():\n",
    "          if count%100 == 0:\n",
    "              print(\"Processed \" + str(count) + \" vectors\")\n",
    "          forward_vector[fn] = vgg_feature_vector(img, model)\n",
    "          count += 1\n",
    "        return forward_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLot4LcsicrR",
    "outputId": "57360e73-5f0d-42ad-d494-539d696697ce"
   },
   "outputs": [],
   "source": [
    "# initialize files, feature vectors, and models\n",
    "is_cae = True # use this to toggle between the two embedding options\n",
    "imgs_dict = get_image_files(path_to_files = '/Users/jennysheng/Documents/museum_images/all_image_data/', size = (224, 224), files = train_files)\n",
    "model = get_model(is_cae) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_feature_vector = feature_vectors(imgs_dict, model, is_cae, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_cae:\n",
    "    image_values = np.array(list(img_feature_vector.values()))\n",
    "    images = image_values.reshape(image_values.shape[0], image_values.shape[2]*image_values.shape[3]*image_values.shape[4])\n",
    "else: \n",
    "    images = list(img_feature_vector.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"/Users/jennysheng/Documents/museum_images/vgg_feature_vectors.pkl\",\"wb\")\n",
    "# pickle.dump(img_feature_vector,f)\n",
    "# f.close()\n",
    "img_feature_vector = pd.read_pickle(r\"/Users/jennysheng/Documents/museum_images/cae_feature_vectors.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_feature_vector.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "wDcF8cGvlzDt",
    "outputId": "2d614022-4fd9-4af3-91af-feec6a5354d7"
   },
   "outputs": [],
   "source": [
    "# elbow plot for kmeans\n",
    "fns = list(img_feature_vector.keys())\n",
    "sum_of_squared_distances = []\n",
    "K = range(1, 50)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(images)\n",
    "    sum_of_squared_distances.append(km.inertia_)\n",
    "    print(\"Processed cluster count K=\" + str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "l_UM_hdV6QH_",
    "outputId": "cdb84086-09f5-491a-d50b-477e52cbe6b3"
   },
   "outputs": [],
   "source": [
    "# plot eblow plot\n",
    "plt.plot(K, sum_of_squared_distances)\n",
    "plt.title('Elbow Method for Optimal Cluster Number')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.savefig(\"/Users/jennysheng/Documents/museum_images/elbow_all_museum_images_no_autoencoder.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save squared distance for reference later\n",
    "with open(\"/Users/jennysheng/Documents/museum_images/vgg_sq_dist.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(sum_of_squared_distances, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a more zoomed in look at the elbow\n",
    "plt.plot(K[:10], sum_of_squared_distances[:10])\n",
    "plt.title('Elbow Method for Optimal Cluster Number')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.show()\n",
    "plt.savefig(\"/Users/jennysheng/Documents/museum_images/elbow_all_museum_images.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "OQluQpMcl_iD",
    "outputId": "67f9a9cf-1c23-4052-c1b9-464fd3340175"
   },
   "outputs": [],
   "source": [
    "# run kmeans using optimal number of clusters\n",
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, init='k-means++')\n",
    "kmeans.fit(images)\n",
    "y_kmeans = kmeans.predict(images)\n",
    "file_names = list(imgs_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save kmeans clusters\n",
    "np.save('/Users/jennysheng/Documents/museum_images/cluster_5_no_ae_data.npy', files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "clusters_features = []\n",
    "cluster_files=[]\n",
    "# iterate and collect all vectors and filenames for each cluster\n",
    "for i in range(n_clusters):\n",
    "    i_cluster = []\n",
    "    i_labels=[]\n",
    "    for idx,j in enumerate(kmeans.labels_):\n",
    "        if j==i:\n",
    "            i_cluster.append(images[idx])\n",
    "            i_labels.append(file_names[idx])\n",
    "    i_cluster = np.array(i_cluster)\n",
    "    clusters_features.append(i_cluster)\n",
    "    cluster_files.append(i_labels)\n",
    "labels=[] # collecting all cluster ids\n",
    "data=[] # collecting all feature vectors\n",
    "files=[] # collecting all file names\n",
    "for idx,i in enumerate(clusters_features):\n",
    "    data.extend(i)\n",
    "    labels.extend([idx for i in range(i.shape[0])])\n",
    "    files.extend(cluster_files[idx])\n",
    "print(np.array(labels).shape)\n",
    "print(np.array(data).shape)\n",
    "print(np.array(files).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C27qIaY6OuEo"
   },
   "outputs": [],
   "source": [
    "image_directory_path = '/Users/jennysheng/Documents/museum_images/all_image_data/'\n",
    "\n",
    "cluster_data = {}\n",
    "for c in range(n_clusters):\n",
    "    cluster_data[c] = []\n",
    "for image_file, cluster in zip(file_names, y_kmeans):\n",
    "    filename = image_directory_path+image_file\n",
    "    cluster_data[cluster].append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(0,n_clusters):\n",
    "    print(\"cluster \" + str(c) + \" size: \" + str(len(cluster_data[c])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image cluster information in dataframe\n",
    "import pandas as pd\n",
    "image_cluster_df = pd.DataFrame(zip(file_names, y_kmeans), columns = [\"imagepath\", \"clusterid\"])\n",
    "image_cluster_df.to_csv(\"/Users/jennysheng/Documents/museum_images/image_cluster_df_cluster_\" + str(n_clusters) + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cluster(df, clusterid, num_shown, num_clusters, save, image_directory_path):\n",
    "    fig = plt.figure(figsize=(14, 14))\n",
    "\n",
    "    cluster = list(df.loc[df.clusterid == clusterid].imagepath)\n",
    "    cluster_random = random.sample(cluster, num_shown)\n",
    "    for i in range(num_shown):\n",
    "        y = fig.add_subplot(6, 5, i+1)\n",
    "        img = mpimg.imread(image_directory_path + cluster[i])\n",
    "        y.imshow(img)\n",
    "        plt.title('cluster ' + str(clusterid))\n",
    "        y.axes.get_xaxis().set_visible(False)\n",
    "        y.axes.get_yaxis().set_visible(False)\n",
    "    if save:\n",
    "        plt.savefig(\"/Users/jennysheng/Documents/museum_images/\"+ str(num_clusters) + \"_clusters_total_cluster_\" + str(clusterid) + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "id": "DpjWhPuC9pau",
    "outputId": "b6a7abab-a924-47ad-f6c4-2ace591e7f16"
   },
   "outputs": [],
   "source": [
    "show_cluster(image_cluster_df, 0, 30, n_clusters, True, image_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "id": "qxx6J6PM9qpX",
    "outputId": "0d2f9b62-3386-4fa2-cbdc-bd9467ff716e"
   },
   "outputs": [],
   "source": [
    "show_cluster(image_cluster_df, 1, 30, n_clusters, True, image_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "id": "LY5qjRIT9sx3",
    "outputId": "099bf04a-27d4-48c3-c7c1-69d93bed668e"
   },
   "outputs": [],
   "source": [
    "show_cluster(image_cluster_df, 2, 30, n_clusters, True, image_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "id": "p_WPpIVx9uvE",
    "outputId": "153bc664-5b29-4598-a623-8484b0ef8299"
   },
   "outputs": [],
   "source": [
    "show_cluster(image_cluster_df, 3, 30, n_clusters, True, image_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "id": "fKL7hHqn9wTL",
    "outputId": "87a08cb5-7be5-4912-813a-ce3952015457"
   },
   "outputs": [],
   "source": [
    "show_cluster(image_cluster_df, 4, 30, n_clusters, True, image_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "id": "8IgmdwXH9xmn",
    "outputId": "8ab407f0-36e9-42be-b288-b5c062adc616"
   },
   "outputs": [],
   "source": [
    "show_cluster(image_cluster_df, 5, 30, n_clusters, True, image_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cluster(image_cluster_df, 6, 30, n_clusters, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save kmeans model\n",
    "kmeans_file = '/Users/jennysheng/Documents/museum_images/kmeans_model_cluster_' + str(n_clusters) + '_1.pkl'\n",
    "joblib.dump(kmeans,kmeans_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Image Cluster Metadata Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis of each cluster\n",
    "merged = pd.read_csv(\"/Users/jennysheng/Documents/museum_images/merged_final_1.csv\")\n",
    "clusters = pd.read_csv(\"/Users/jennysheng/Documents/museum_images/image_cluster_df_cluster_\" + str(n_clusters) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get cluster meta data\n",
    "def get_cluster_meta_data(merged_df, cluster_df, clusterid):\n",
    "    cluster = list(cluster_df.loc[cluster_df.clusterid == clusterid].imagepath)\n",
    "    all_repositories = {\"met_\":\"Metropolitan Museum of Art, New York, NY\", \"mia_\":\"Minneapolis Institute of Art\", \"puam\":\"Princeton University Art Museum\", \"moma\":\"The Museum of Modern Art\", \"cmoa\":\"Carnegie Museum of Art\"}\n",
    "    data = pd.DataFrame()\n",
    "    for i in range(len(cluster)):\n",
    "        imagepath = cluster[i]\n",
    "        id = imagepath[:-9]\n",
    "        repo = imagepath[-8:-4]\n",
    "        meta_data = merged_df.loc[merged_df.repository == all_repositories[repo]]\n",
    "        meta_data_with_id = meta_data.loc[meta_data.objectid == id]\n",
    "        if len(meta_data_with_id) == 0:\n",
    "            meta_data_with_id = meta_data.loc[meta_data.objectid == int(id)]\n",
    "        data = data.append(meta_data_with_id)\n",
    "    print(len(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = []\n",
    "for i in range(n_clusters):\n",
    "    print(\"Cluster \" + str(i) + \" data:\")\n",
    "    cluster_data_i = get_cluster_meta_data(merged, clusters, i)\n",
    "    cluster_data.append(cluster_data_i)\n",
    "    print(cluster_data_i.repository.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get value counts for characteristics or fields\n",
    "def get_characteristic_frequency_in_cluster(cluster_data, characteristic):\n",
    "    if characteristic == \"tags\":\n",
    "        met = cluster_data.loc[cluster_data.repository == \"Metropolitan Museum of Art, New York, NY\"]\n",
    "        met_characteristics = pd.DataFrame(met[characteristic])\n",
    "        met_characteristics[\"objectid\"] = met_characteristics.index\n",
    "        met_characteristics = pd.melt(met_characteristics, id_vars=['objectid'], value_vars=met_characteristics.columns.values[:-1])\n",
    "        multihot = pd.get_dummies(met_characteristics.set_index('objectid')['value']).max(level=0).reset_index()\n",
    "    if characteristic == \"accessionyear\":\n",
    "        cluster_data_characteristics = pd.DataFrame(cluster_data[characteristic])\n",
    "        cluster_data_characteristics[\"objectid\"] = cluster_data_characteristics.index\n",
    "        cluster_data_characteristics = pd.melt(cluster_data_characteristics, id_vars=['objectid'], value_vars=cluster_data_characteristics.columns.values[:-1])\n",
    "        multihot = pd.get_dummies(cluster_data_characteristics.set_index('objectid')['value']).max(level=0).reset_index()\n",
    "    else:\n",
    "        cluster_data_characteristics = cluster_data[characteristic].str.split(\"|\", expand=True)\n",
    "        cluster_data_characteristics[\"objectid\"] = cluster_data_characteristics.index\n",
    "        cluster_data_characteristics = pd.melt(cluster_data_characteristics, id_vars=['objectid'], value_vars=cluster_data_characteristics.columns.values[:-1])\n",
    "        multihot = pd.get_dummies(cluster_data_characteristics.set_index('objectid')['value']).max(level=0).reset_index()\n",
    "    return multihot\n",
    "\n",
    "def cluster_characteristics(clusterid, merged_df, cluster_df, characteristic, num_shown, single_cluster_data):\n",
    "    cluster_data = single_cluster_data[clusterid]\n",
    "    multihot_cluster = get_characteristic_frequency_in_cluster(cluster_data, characteristic)\n",
    "    counts = dict(multihot_cluster[[c for c in multihot_cluster.columns if not c == \"objectid\"]].sum())\n",
    "    counts = sorted(counts.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    print(counts[:num_shown])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_clusters):\n",
    "    print(\"Cluster \" + str(i))\n",
    "    cluster_characteristics(i, merged, clusters, \"culture\", 20, cluster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_clusters):\n",
    "    print(\"Cluster \" + str(i))\n",
    "    cluster_characteristics(i, merged, clusters, \"tags\", 20, cluster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_clusters):\n",
    "    print(\"Cluster \" + str(i))\n",
    "    cluster_characteristics(i, merged, clusters, \"artistdisplayname\", 20, cluster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_clusters):\n",
    "    print(\"Cluster \" + str(i))\n",
    "    cluster_characteristics(i, merged, clusters, \"classification\", 20, cluster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_clusters):\n",
    "    print(\"Cluster \" + str(i))\n",
    "    cluster_characteristics(i, merged, clusters, \"accessionyear\", 20, cluster_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **t-SNE Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform dimensionality reduction to 2D using t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, verbose=2).fit_transform(images)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tx = tsne[:, 0]\n",
    "tx = (tx - np.min(tx))/(np.max(tx) - np.min(tx))\n",
    "ty = tsne[:, 1]\n",
    "ty = (ty - np.min(ty))/(np.max(ty) - np.min(ty))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "colors =[\"blue\", \"red\", \"yellow\", \"green\", \"purple\", \"orange\", \"pink\", \"magenta\", \"teal\", \"brown\"]\n",
    "image_cluster_df = pd.read_csv(\"/Users/jennysheng/Documents/museum_images/image_cluster_df_cluster_\" + str(n_clusters) + \".csv\")\n",
    "\n",
    "\n",
    "for clusterid in range(n_clusters):\n",
    "    cluster = image_cluster_df.loc[image_cluster_df.clusterid == clusterid]\n",
    "    cluster_dict = dict(zip(file_names, y_kmeans))\n",
    "    indices = [i for i, (k, v) in enumerate(cluster_dict.items()) if v == clusterid]\n",
    "    ax.scatter(tx[indices], ty[indices], c=colors[clusterid], label=clusterid)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(\"2D T-SNE Visualization of Clusters\")\n",
    "\n",
    "plt.savefig(\"/Users/jennysheng/Documents/museum_images/cae_cluster_visualization_cluster_\" + str(n_clusters) + \".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Find Similar Images Using K-NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal number of neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_params = {'n_neighbors': range(0, 20)}\n",
    "X = tsne  \n",
    "y = y_kmeans\n",
    "knn = KNeighborsClassifier()\n",
    "gs = GridSearchCV(knn, grid_params, verbose = 1, cv = 3, n_jobs = 3)\n",
    "gs.fit(X,y)\n",
    "print (gs.best_score_)\n",
    "print (gs.best_params_)\n",
    "print (gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run knn model on optimal number of neighbors and save knn model\n",
    "n_neighbors=12\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors,algorithm='ball_tree',n_jobs=-1)\n",
    "knn.fit(np.array(data),np.array(labels))\n",
    "knn_file = '/Users/jennysheng/Documents/museum_images/knn_model_clusters_' + str(n_clusters) + \"_neighbors_\" + str(n_neighbors) + \"_1.pkl\"\n",
    "joblib.dump(knn,knn_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find similar neigbors\n",
    "def predictions(query, N, model, knn, files, image_dir_path, size):\n",
    "    image = cv2.resize(cv2.imread(image_dir_path+query), size)\n",
    "    feature = feature_vector(image, model)\n",
    "    res = knn.kneighbors(feature.reshape(1,-1),return_distance=True,n_neighbors=N)\n",
    "    return [files[i] for i in list(res[1][0])[1:][:N+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show similar images in a grid-like plot\n",
    "def show_similar_images(images):\n",
    "    fig = plt.figure(figsize=(14, 14))\n",
    "    for i in range(len(images)):\n",
    "        y = fig.add_subplot(6, 5, i+1)\n",
    "        img = mpimg.imread(\"/Users/jennysheng/Documents/museum_images/all_image_data/\" + images[i])\n",
    "        y.imshow(img)\n",
    "        y.axes.get_xaxis().set_visible(False)\n",
    "        y.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 10 # feel free to change this number to any index between 0 and 499 to see results\n",
    "img = mpimg.imread(\"/Users/jennysheng/Documents/museum_images/all_image_data/\" + test_files[num])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_images = predictions(test_files[num], 7, model, knn, files, image_directory_path, (224, 224))\n",
    "show_similar_images(similar_images)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "image_clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
